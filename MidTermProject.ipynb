{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d0eda07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import requests\n",
    "# from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "957a4833",
   "metadata": {},
   "outputs": [],
   "source": [
    "# url = 'https://www.apple.com/mac/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d888828",
   "metadata": {},
   "outputs": [],
   "source": [
    "# page = requests.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b7a6b287",
   "metadata": {},
   "outputs": [],
   "source": [
    "# page.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59bda9c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# soup = BeautifulSoup(page.content , 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6ad07535",
   "metadata": {},
   "outputs": [],
   "source": [
    "# soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "00f04d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# content = soup.findAll(attrs = {'class' : 'device-content'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c789d933",
   "metadata": {},
   "outputs": [],
   "source": [
    "# content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fd5e766f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# content[0].text.replace('\\n' , ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7bca6ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# content[1].text.replace('\\n' , ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f8e8dfbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# content[2].text.replace('\\n' , ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4c835597",
   "metadata": {},
   "outputs": [],
   "source": [
    "# content[3].text.replace('\\n' , ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a8af44c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# content[4].text.replace('\\n' , ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "78eaf080",
   "metadata": {},
   "outputs": [],
   "source": [
    "# content[5].text.replace('\\n' , ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ee09b9c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# content[6].text.replace('\\n' , ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3d88c16b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# url = 'https://www.czone.com.pk/laptops-apple-laptops-pakistan-pt.281.aspx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c729d4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# page = requests.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0ea0b476",
   "metadata": {},
   "outputs": [],
   "source": [
    "# page.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3990d8e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# soup = BeautifulSoup(page.content , 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "223cbb4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "35fb461a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# content = soup.findAll(attrs = {'class' : 'row categoryProduct xsResponse clearfix'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b5462208",
   "metadata": {},
   "outputs": [],
   "source": [
    "# content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d192b6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# products=[] \n",
    "# prices=[]  \n",
    "# ratings=[]\n",
    "\n",
    "# for a in soup.findAll('div',attrs={'class':'row categoryProduct xsResponse clearfix'}):\n",
    "#     print (a)\n",
    "#     products=a.find('a', attrs={'class':'product-code no-padding'})\n",
    "#     price=a.find('div', attrs={'class':'price'})\n",
    "#     rating=a.find('div', attrs={'class':'rating'})\n",
    "#     products.append(products.text)\n",
    "#     prices.append(price.text)\n",
    "#     ratings.append(rating.text)\n",
    "    \n",
    "# df = pd.DataFrame({'Product Name':products,'Price':prices,'Rating':ratings})\n",
    "# df.to_csv('products.csv', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b04293b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# products = soup.find(attrs = {'class' : 'row categoryProduct xsResponse clearfix'}).text.replace('\\n' , '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9f23d9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# price = soup.find(attrs = {'class' : 'price'}).text.replace('\\n' , '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b0491e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ratings = soup.find(attrs = {'class' : 'rating'}).text.replace('\\n' , '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "98c74ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = [[url , products , price , ratings]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adba5b71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3de5f105",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.DataFrame(data , columns=['url','products','price','ratings'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ee80bd1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3fb884af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv('products.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "19edb5e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(1,11):\n",
    "#     url = 'https://www.czone.com.pk/laptops-apple-laptops-pakistan-pt.281.aspx' + str(i)\n",
    "#     page = requests.get(url)\n",
    "#     if(True):\n",
    "#         print('Data Fetched Successfully' , i)\n",
    "#         soup = BeautifulSoup(page.content , 'html.parser')\n",
    "#         products = soup.find(attrs = {'class' : 'row categoryProduct xsResponse clearfix'})\n",
    "#         price = soup.find(attrs = {'class' : 'price'}) \n",
    "#         ratings = soup.find(attrs = {'class' : 'rating'}) \n",
    "#         data = ([[url , products , price , ratings]])\n",
    "#     else:\n",
    "#         print('url not found' , i)\n",
    "        \n",
    "# df = pd.DataFrame(data , columns=['url','products','price','ratings'])\n",
    "# df.to_csv('laptop.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e4ba50",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a3e17a46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'crumb' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "'crumb' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "\n",
      "EnvironmentLocationNotFound: Not a conda environment: D:\\New\n",
      "\n",
      "'crumb' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "'crumb' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "\n",
      "EnvironmentLocationNotFound: Not a conda environment: D:\\New\n",
      "\n",
      "'crumb' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "'crumb' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "\n",
      "EnvironmentLocationNotFound: Not a conda environment: D:\\New\n",
      "\n",
      "'crumb' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "'crumb' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "\n",
      "EnvironmentLocationNotFound: Not a conda environment: D:\\New\n",
      "\n",
      "'crumb' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "'crumb' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "\n",
      "EnvironmentLocationNotFound: Not a conda environment: D:\\New\n",
      "\n",
      "'crumb' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "'crumb' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "\n",
      "EnvironmentLocationNotFound: Not a conda environment: D:\\New\n",
      "\n"
     ]
    }
   ],
   "source": [
    "conda install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d6adc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from selenium import webdriver\n",
    "# from bs4 import BeautifulSoup\n",
    "# import pandas as pd\n",
    "\n",
    "# browser =  r\"C:\\Users\\DELL\\Desktop\\web driver\\chrome.exe\")\n",
    "# All_url=[] #List to store all the urls that we are going to use to scrap data\n",
    "\n",
    "# df = pd.read_csv('laptop.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "512a1a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# chrome_driver = r'C:\\Users\\DELL\\Desktop\\web driver\\chromedriver.exe'\n",
    "# driver = webdriver.Chrome(chrome_driver)\n",
    "# driver.get('https://www.google.com')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84bf2412",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import selenium\n",
    "# from selenium import webdriver\n",
    "# from time import sleep\n",
    "\n",
    "# class MyBot:\n",
    "#     def __init__(self):\n",
    "#         self.driver = webdriver.com()\n",
    "#         self.driver.get('https://www.google.com')\n",
    "#         self.driver.maximize_window()\n",
    "#         print(self.driver.title)\n",
    "#         sleep(1)\n",
    "        \n",
    "# MyBot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "01c5c4d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d8ef800a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-d58d954b69fd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[0murl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'https://www.ebay.com/sch/i.html?_from=R40&_nkw=macbook&_sacat=0&_pgn='\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'&rt=nc'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[0mreq\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m     \u001b[0msoup\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontent\u001b[0m \u001b[1;33m,\u001b[0m \u001b[1;34m'html.parser'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msoup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfindAll\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'div'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'class'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;34m's-item__info clearfix'\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m         \u001b[0mproducts\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'span'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'class'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;34m'BOLD'\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\New folder (2)\\lib\\site-packages\\bs4\\__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, markup, features, builder, parse_only, from_encoding, exclude_encodings, element_classes, **kwargs)\u001b[0m\n\u001b[0;32m    340\u001b[0m         \u001b[0mrejections\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    341\u001b[0m         \u001b[0msuccess\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 342\u001b[1;33m         for (self.markup, self.original_encoding, self.declared_html_encoding,\n\u001b[0m\u001b[0;32m    343\u001b[0m          \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontains_replacement_characters\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m              self.builder.prepare_markup(\n",
      "\u001b[1;32mD:\\New folder (2)\\lib\\site-packages\\bs4\\builder\\_htmlparser.py\u001b[0m in \u001b[0;36mprepare_markup\u001b[1;34m(self, markup, user_specified_encoding, document_declared_encoding, exclude_encodings)\u001b[0m\n\u001b[0;32m    361\u001b[0m         \u001b[1;31m# Ask UnicodeDammit to sniff the most likely encoding.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    362\u001b[0m         \u001b[0mtry_encodings\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0muser_specified_encoding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdocument_declared_encoding\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 363\u001b[1;33m         dammit = UnicodeDammit(markup, try_encodings, is_html=True,\n\u001b[0m\u001b[0;32m    364\u001b[0m                                exclude_encodings=exclude_encodings)\n\u001b[0;32m    365\u001b[0m         yield (dammit.markup, dammit.original_encoding,\n",
      "\u001b[1;32mD:\\New folder (2)\\lib\\site-packages\\bs4\\dammit.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, markup, override_encodings, smart_quotes_to, is_html, exclude_encodings)\u001b[0m\n\u001b[0;32m    443\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    444\u001b[0m         \u001b[0mu\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 445\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mencoding\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetector\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencodings\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    446\u001b[0m             \u001b[0mmarkup\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetector\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmarkup\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    447\u001b[0m             \u001b[0mu\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_convert_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\New folder (2)\\lib\\site-packages\\bs4\\dammit.py\u001b[0m in \u001b[0;36mencodings\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    307\u001b[0m         \u001b[1;31m# encoding.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    308\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchardet_encoding\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 309\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchardet_encoding\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mchardet_dammit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmarkup\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    310\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_usable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchardet_encoding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtried\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    311\u001b[0m             \u001b[1;32myield\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchardet_encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\New folder (2)\\lib\\site-packages\\bs4\\dammit.py\u001b[0m in \u001b[0;36mchardet_dammit\u001b[1;34m(s)\u001b[0m\n\u001b[0;32m     35\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mchardet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'encoding'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m         \u001b[1;31m#import chardet.constants\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m         \u001b[1;31m#chardet.constants._debug = 1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\New folder (2)\\lib\\site-packages\\chardet\\__init__.py\u001b[0m in \u001b[0;36mdetect\u001b[1;34m(byte_str)\u001b[0m\n\u001b[0;32m     39\u001b[0m             \u001b[0mbyte_str\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbytearray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbyte_str\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m     \u001b[0mdetector\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mUniversalDetector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m     \u001b[0mdetector\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbyte_str\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdetector\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\New folder (2)\\lib\\site-packages\\chardet\\universaldetector.py\u001b[0m in \u001b[0;36mfeed\u001b[1;34m(self, byte_str)\u001b[0m\n\u001b[0;32m    209\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_charset_probers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mLatin1Prober\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mprober\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_charset_probers\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 211\u001b[1;33m                 \u001b[1;32mif\u001b[0m \u001b[0mprober\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbyte_str\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mProbingState\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFOUND_IT\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    212\u001b[0m                     self.result = {'encoding': prober.charset_name,\n\u001b[0;32m    213\u001b[0m                                    \u001b[1;34m'confidence'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mprober\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_confidence\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\New folder (2)\\lib\\site-packages\\chardet\\charsetgroupprober.py\u001b[0m in \u001b[0;36mfeed\u001b[1;34m(self, byte_str)\u001b[0m\n\u001b[0;32m     69\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mprober\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mactive\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m                 \u001b[1;32mcontinue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 71\u001b[1;33m             \u001b[0mstate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprober\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbyte_str\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     72\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m                 \u001b[1;32mcontinue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\New folder (2)\\lib\\site-packages\\chardet\\mbcharsetprober.py\u001b[0m in \u001b[0;36mfeed\u001b[1;34m(self, byte_str)\u001b[0m\n\u001b[0;32m     76\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistribution_analyzer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_last_char\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchar_len\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 78\u001b[1;33m                     self.distribution_analyzer.feed(byte_str[i - 1:i + 1],\n\u001b[0m\u001b[0;32m     79\u001b[0m                                                     char_len)\n\u001b[0;32m     80\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from selenium import webdriver \n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import requests\n",
    "from time import sleep\n",
    "\n",
    "# browser =  r\"C:\\Users\\DELL\\Desktop\\web driver\\chrome.exe\"\n",
    "\n",
    "# print(soup.prettify())\n",
    "# print(soup)\n",
    "\n",
    "url_list = []\n",
    "# df = pd.read_csv('laptop.csv')\n",
    "# df\n",
    "\n",
    "url = 'https://www.ebay.com/sch/i.html?_from=R40&_trksid=p2540003.m570.l1313&_nkw=macbook&_sacat=0'\n",
    "Products=[] \n",
    "Prices=[]  \n",
    "Shipping=[]\n",
    "Location=[]\n",
    "Item=[]\n",
    "Sold=[]\n",
    "Subtitle=[]\n",
    "\n",
    "# content = driver.page_source\n",
    "for i in range(1,101):\n",
    "    print(i)\n",
    "    url = 'https://www.ebay.com/sch/i.html?_from=R40&_nkw=macbook&_sacat=0&_pgn='+str(i)+'&rt=nc'\n",
    "    req = requests.get(url)\n",
    "    soup = BeautifulSoup(req.content , 'html.parser')\n",
    "    for a in soup.findAll('div',attrs={'class':'s-item__info clearfix'}):\n",
    "        products=a.find('span', attrs={'class':'BOLD'})\n",
    "        price=a.find('div', attrs={'class':'s-item__detail s-item__detail--primary'})\n",
    "        shipping=a.find('div', attrs={'class':'s-item__shipping s-item__logisticsCost'})\n",
    "        location=a.find('span' , attrs={'class':'s-item__location s-item__itemLocation'})\n",
    "        item=a.find('span',attrs={'class':'s-item__gsp-info s-item__gspInfo'})\n",
    "        sold=a.find('span',attrs={'class':'BOLD'})\n",
    "        subtitle=a.find('div',attrs={'class':'s-item__subtitle'})\n",
    "        try:\n",
    "            Products.append(products.text)\n",
    "            products = products.text\n",
    "        except:\n",
    "            Products.append(\"Null\")\n",
    "            products = \"Null\"\n",
    "        try:\n",
    "            Prices.append(price.text)\n",
    "            price = price.text\n",
    "        except:\n",
    "            Prices.append(\"Null\")\n",
    "            price = \"Null\"\n",
    "        try:\n",
    "            Shipping.append(shipping.text)\n",
    "            shipping = shipping.text\n",
    "        except:\n",
    "            Shipping.append(\"Null\")\n",
    "            shipping = \"Null\"\n",
    "        try:\n",
    "            Location.append(location.text)\n",
    "            location = location.text\n",
    "        except:\n",
    "            Location.append(\"Null\")\n",
    "            location = \"Null\"\n",
    "        try:\n",
    "            Item.append(item.text)\n",
    "            item = item.text\n",
    "        except:\n",
    "            Item.append(\"Null\")\n",
    "            item = \"Null\"\n",
    "        try:\n",
    "            Sold.append(sold.text)\n",
    "            sold = sold.text\n",
    "        except:\n",
    "            Sold.append(\"Null\")\n",
    "            sold = \"Null\"\n",
    "        try:\n",
    "            Subtitle.append(subtitle.text)\n",
    "            subtitle = subtitle.text\n",
    "        except:\n",
    "            Subtitle.append(\"Null\")\n",
    "            subtitle = \"Null\"\n",
    "        df = pd.DataFrame({'Product Name':[products],'Price':[price] ,\n",
    "                           'Shipping':[shipping],'Location':[location],\n",
    "                           'Item':[item],'Sold':[sold],'Subtitle':[subtitle]})\n",
    "        df.to_csv('products.csv', header=False, mode = 'a' ,index=False, encoding='utf-8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e08137e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
