{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d0eda07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import requests\n",
    "# from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "957a4833",
   "metadata": {},
   "outputs": [],
   "source": [
    "# url = 'https://www.apple.com/mac/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d888828",
   "metadata": {},
   "outputs": [],
   "source": [
    "# page = requests.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b7a6b287",
   "metadata": {},
   "outputs": [],
   "source": [
    "# page.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59bda9c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# soup = BeautifulSoup(page.content , 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6ad07535",
   "metadata": {},
   "outputs": [],
   "source": [
    "# soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "00f04d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# content = soup.findAll(attrs = {'class' : 'device-content'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c789d933",
   "metadata": {},
   "outputs": [],
   "source": [
    "# content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fd5e766f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# content[0].text.replace('\\n' , ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7bca6ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# content[1].text.replace('\\n' , ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f8e8dfbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# content[2].text.replace('\\n' , ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4c835597",
   "metadata": {},
   "outputs": [],
   "source": [
    "# content[3].text.replace('\\n' , ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a8af44c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# content[4].text.replace('\\n' , ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "78eaf080",
   "metadata": {},
   "outputs": [],
   "source": [
    "# content[5].text.replace('\\n' , ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ee09b9c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# content[6].text.replace('\\n' , ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3d88c16b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# url = 'https://www.czone.com.pk/laptops-apple-laptops-pakistan-pt.281.aspx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c729d4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# page = requests.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0ea0b476",
   "metadata": {},
   "outputs": [],
   "source": [
    "# page.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3990d8e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# soup = BeautifulSoup(page.content , 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "223cbb4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "35fb461a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# content = soup.findAll(attrs = {'class' : 'row categoryProduct xsResponse clearfix'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b5462208",
   "metadata": {},
   "outputs": [],
   "source": [
    "# content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d192b6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# products=[] \n",
    "# prices=[]  \n",
    "# ratings=[]\n",
    "\n",
    "# for a in soup.findAll('div',attrs={'class':'row categoryProduct xsResponse clearfix'}):\n",
    "#     print (a)\n",
    "#     products=a.find('a', attrs={'class':'product-code no-padding'})\n",
    "#     price=a.find('div', attrs={'class':'price'})\n",
    "#     rating=a.find('div', attrs={'class':'rating'})\n",
    "#     products.append(products.text)\n",
    "#     prices.append(price.text)\n",
    "#     ratings.append(rating.text)\n",
    "    \n",
    "# df = pd.DataFrame({'Product Name':products,'Price':prices,'Rating':ratings})\n",
    "# df.to_csv('products.csv', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b04293b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# products = soup.find(attrs = {'class' : 'row categoryProduct xsResponse clearfix'}).text.replace('\\n' , '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9f23d9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# price = soup.find(attrs = {'class' : 'price'}).text.replace('\\n' , '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b0491e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ratings = soup.find(attrs = {'class' : 'rating'}).text.replace('\\n' , '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "98c74ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = [[url , products , price , ratings]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adba5b71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3de5f105",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.DataFrame(data , columns=['url','products','price','ratings'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ee80bd1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3fb884af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv('products.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "19edb5e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(1,11):\n",
    "#     url = 'https://www.czone.com.pk/laptops-apple-laptops-pakistan-pt.281.aspx' + str(i)\n",
    "#     page = requests.get(url)\n",
    "#     if(True):\n",
    "#         print('Data Fetched Successfully' , i)\n",
    "#         soup = BeautifulSoup(page.content , 'html.parser')\n",
    "#         products = soup.find(attrs = {'class' : 'row categoryProduct xsResponse clearfix'})\n",
    "#         price = soup.find(attrs = {'class' : 'price'}) \n",
    "#         ratings = soup.find(attrs = {'class' : 'rating'}) \n",
    "#         data = ([[url , products , price , ratings]])\n",
    "#     else:\n",
    "#         print('url not found' , i)\n",
    "        \n",
    "# df = pd.DataFrame(data , columns=['url','products','price','ratings'])\n",
    "# df.to_csv('laptop.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e4ba50",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a3e17a46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'crumb' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "'crumb' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "\n",
      "EnvironmentLocationNotFound: Not a conda environment: D:\\New\n",
      "\n",
      "'crumb' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "'crumb' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "\n",
      "EnvironmentLocationNotFound: Not a conda environment: D:\\New\n",
      "\n",
      "'crumb' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "'crumb' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "\n",
      "EnvironmentLocationNotFound: Not a conda environment: D:\\New\n",
      "\n",
      "'crumb' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "'crumb' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "\n",
      "EnvironmentLocationNotFound: Not a conda environment: D:\\New\n",
      "\n",
      "'crumb' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "'crumb' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "\n",
      "EnvironmentLocationNotFound: Not a conda environment: D:\\New\n",
      "\n",
      "'crumb' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "'crumb' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "\n",
      "EnvironmentLocationNotFound: Not a conda environment: D:\\New\n",
      "\n"
     ]
    }
   ],
   "source": [
    "conda install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d6adc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from selenium import webdriver\n",
    "# from bs4 import BeautifulSoup\n",
    "# import pandas as pd\n",
    "\n",
    "# browser =  r\"C:\\Users\\DELL\\Desktop\\web driver\\chrome.exe\")\n",
    "# All_url=[] #List to store all the urls that we are going to use to scrap data\n",
    "\n",
    "# df = pd.read_csv('laptop.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "512a1a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# chrome_driver = r'C:\\Users\\DELL\\Desktop\\web driver\\chromedriver.exe'\n",
    "# driver = webdriver.Chrome(chrome_driver)\n",
    "# driver.get('https://www.google.com')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84bf2412",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import selenium\n",
    "# from selenium import webdriver\n",
    "# from time import sleep\n",
    "\n",
    "# class MyBot:\n",
    "#     def __init__(self):\n",
    "#         self.driver = webdriver.com()\n",
    "#         self.driver.get('https://www.google.com')\n",
    "#         self.driver.maximize_window()\n",
    "#         print(self.driver.title)\n",
    "#         sleep(1)\n",
    "        \n",
    "# MyBot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "01c5c4d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d8ef800a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver \n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import requests\n",
    "import time\n",
    "\n",
    "# browser =  r\"C:\\Users\\DELL\\Desktop\\web driver\\chrome.exe\"\n",
    "\n",
    "# print(soup.prettify())\n",
    "# print(soup)\n",
    "\n",
    "url_list = []\n",
    "# df = pd.read_csv('laptop.csv')\n",
    "# df\n",
    "\n",
    "url = 'https://www.ebay.com/sch/i.html?_from=R40&_trksid=p2540003.m570.l1313&_nkw=macbook&_sacat=0'\n",
    "Products=[] \n",
    "Prices=[]  \n",
    "Shipping=[]\n",
    "Location=[]\n",
    "Item=[]\n",
    "Sold=[]\n",
    "Subtitle=[]\n",
    "\n",
    "# content = driver.page_source\n",
    "for i in range(1,101):\n",
    "    print(i)\n",
    "    url = 'https://www.ebay.com/sch/i.html?_from=R40&_nkw=macbook&_sacat=0&_pgn='+str(i)+'&rt=nc'\n",
    "    time.sleep(5)\n",
    "    req = requests.get(url)\n",
    "    soup = BeautifulSoup(req.content , 'html.parser')\n",
    "    for a in soup.findAll('div',attrs={'class':'s-item__info clearfix'}):\n",
    "        products=a.find('span', attrs={'class':'BOLD'})\n",
    "        price=a.find('div', attrs={'class':'s-item__detail s-item__detail--primary'})\n",
    "        shipping=a.find('div', attrs={'class':'s-item__shipping s-item__logisticsCost'})\n",
    "        location=a.find('span' , attrs={'class':'s-item__location s-item__itemLocation'})\n",
    "        item=a.find('span',attrs={'class':'s-item__gsp-info s-item__gspInfo'})\n",
    "        sold=a.find('span',attrs={'class':'BOLD'})\n",
    "        subtitle=a.find('div',attrs={'class':'s-item__subtitle'})\n",
    "        try:\n",
    "            Products.append(products.text)\n",
    "            products = products.text\n",
    "        except:\n",
    "            Products.append(\"Null\")\n",
    "            products = \"Null\"\n",
    "        try:\n",
    "            Prices.append(price.text)\n",
    "            price = price.text\n",
    "        except:\n",
    "            Prices.append(\"Null\")\n",
    "            price = \"Null\"\n",
    "        try:\n",
    "            Shipping.append(shipping.value)\n",
    "            shipping = shipping.text\n",
    "        except:\n",
    "            Shipping.append(\"Null\")\n",
    "            shipping = \"Null\"\n",
    "        try:\n",
    "            Location.append(location.text)\n",
    "            location = location.text\n",
    "        except:\n",
    "            Location.append(\"Null\")\n",
    "            location = \"Null\"\n",
    "        try:\n",
    "            Item.append(item.text)\n",
    "            item = item.text\n",
    "        except:\n",
    "            Item.append(\"Null\")\n",
    "            item = \"Null\"\n",
    "        try:\n",
    "            Sold.append(sold.text)\n",
    "            sold = sold.text\n",
    "        except:\n",
    "            Sold.append(\"Null\")\n",
    "            sold = \"Null\"\n",
    "        try:\n",
    "            Subtitle.append(subtitle.text)\n",
    "            subtitle = subtitle.text\n",
    "        except:\n",
    "            Subtitle.append(\"Null\")\n",
    "            subtitle = \"Null\"\n",
    "        df = pd.DataFrame({'Product Name':[products],'Price':[price] ,\n",
    "                           'Shipping':[shipping],'Location':[location],\n",
    "                           'Item':[item],'Sold':[sold],'Subtitle':[subtitle]})\n",
    "        df.to_csv('products.csv', header=False, mode = 'a' ,index=False, encoding='utf-8')\n",
    "\n",
    "Phone=[] \n",
    "PPrice=[]  \n",
    "PShipping=[]\n",
    "PLocation=[]\n",
    "PItem=[]\n",
    "Prating=[]\n",
    "PSubtitle=[]\n",
    "for i in range(1,91):\n",
    "    print(i)\n",
    "    url = 'https://www.ebay.com/sch/i.html?_nkw=iphone&_sop=12&_pgn='+str(i)\n",
    "    req = requests.get(url)\n",
    "    soup = BeautifulSoup(req.content , 'html.parser')\n",
    "    for a in soup.findAll('div',attrs={'class':'s-item__info clearfix'}):\n",
    "        time.sleep(5)\n",
    "        phone=a.find('h3', attrs={'class':'s-item__title'})\n",
    "        pprice=a.find('span', attrs={'class':'s-item__price'})\n",
    "        pshipping=a.find('span', attrs={'class':'s-item__shipping s-item__logisticsCost'})\n",
    "        plocation=a.find('span' , attrs={'class':'s-item__location s-item__itemLocation'})\n",
    "        pitem=a.find('span',attrs={'class':'s-item__gsp-info s-item__gspInfo'})\n",
    "        prating=a.find('div',attrs={'class':'x-star-rating'})\n",
    "        psubtitle=a.find('div',attrs={'class':'s-item__subtitle'})\n",
    "        try:\n",
    "            Phone.append(phone.text)\n",
    "            phone = phone.text\n",
    "        except:\n",
    "            Phone.append(\"Null\")\n",
    "            phone = \"Null\"\n",
    "        try:\n",
    "            PPrice.append(pprice.text)\n",
    "            pprice = pprice.text\n",
    "        except:\n",
    "            PPrice.append(\"Null\")\n",
    "            price = \"Null\"\n",
    "        try:\n",
    "            PShipping.append(pshipping.value)\n",
    "            pshipping = pshipping.text\n",
    "        except:\n",
    "            PShipping.append(\"Null\")\n",
    "            pshipping = \"Null\"\n",
    "        try:\n",
    "            PLocation.append(plocation.text)\n",
    "            plocation = plocation.text\n",
    "        except:\n",
    "            PLocation.append(\"Null\")\n",
    "            plocation = \"Null\"\n",
    "        try:\n",
    "            PItem.append(pitem.text)\n",
    "            pitem = pitem.text\n",
    "        except:\n",
    "            PItem.append(\"Null\")\n",
    "            pitem = \"Null\"\n",
    "        try:\n",
    "            Prating.append(prating.text)\n",
    "            prating = prating.text\n",
    "        except:\n",
    "            Prating.append(\"Null\")\n",
    "            prating = \"Null\"\n",
    "        try:\n",
    "            PSubtitle.append(psubtitle.text)\n",
    "            psubtitle = psubtitle.text\n",
    "        except:\n",
    "            PSubtitle.append(\"Null\")\n",
    "            psubtitle = \"Null\"\n",
    "        df = pd.DataFrame({'Product Name':[phone],'Price':[pprice] ,\n",
    "                           'Shipping':[pshipping],'Location':[plocation],\n",
    "                           'Item':[pitem],'Rating':[prating],'Subtitle':[psubtitle]})\n",
    "        df.to_csv('products.csv', header=False, mode = 'a' ,index=False, encoding='utf-8')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd7730e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
